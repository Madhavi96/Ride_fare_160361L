# -*- coding: utf-8 -*-
"""Copy of xgboost.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1syV8nuHUQAbiwQ5k9mnCyK4HcmfceA6U
"""

import pandas as pd
import numpy as np
from datetime import datetime
from sklearn.preprocessing import StandardScaler,MinMaxScaler
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

# Load libraries
from pandas import read_csv
from pandas.plotting import scatter_matrix
from matplotlib import pyplot

from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC

X_train = pd.read_csv('/content/drive/My Drive/Ride_Fare/train.csv',index_col='tripid',)

X_train

X_train.info()

########### distance harvesian
'''
num_rows=X_train.shape[0]
hour_list = []

for i in range(num_rows):
  pick_time = X_train.iloc[i]['pickup_time'] 
  hr = datetime.strptime(pick_time,'%m/%d/%Y %H:%M').hour
  hour_list.append(hr)

X_train['pick_h'] = hour_list
'''

X_train.drop('drop_time',axis = 1,inplace=True)
X_train.drop('pickup_time',axis = 1,inplace=True)
#X_train.drop('additional_fare',axis = 1,inplace=True)

from numpy import cos, sin, arcsin, sqrt
from math import radians

def haversine(pick_lon,pick_lat,drop_lon,drop_lat):
    lon1 = pick_lon
    lat1 = pick_lat
    lon2 =drop_lon
    lat2 = drop_lat

    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])
    dlon = lon2 - lon1 
    dlat = lat2 - lat1 
    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2
    c = 2 * arcsin(sqrt(a)) 
    km = 6367 * c

    return km

########### distance harvesian

num_rows=X_train.shape[0]
distance_list = []

for i in range(num_rows):
  pick_lon = X_train.iloc[i]['pick_lon'] 
  pick_lat = X_train.iloc[i]['pick_lat'] 
  drop_lon =  X_train.iloc[i]['drop_lon']
  drop_lat =  X_train.iloc[i]['drop_lat']
  dist = haversine(pick_lon,pick_lat,drop_lon,drop_lat)
  distance_list.append(dist)

X_train['distance'] = distance_list



X_train.drop('pick_lat',axis = 1,inplace=True)
X_train.drop('pick_lon',axis = 1,inplace=True)
X_train.drop('drop_lat',axis = 1,inplace=True)
X_train.drop('drop_lon',axis = 1,inplace=True)

X_train['label'] = X_train['label'].replace({'correct':1 , 'incorrect':0})

!pip install xgboost

from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

Y = X_train['label']
X_train.drop('label',axis=1,inplace=True)

X= X_train

X.reset_index(drop=True, inplace=True)

seed = 7
test_size = 0.33
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed,shuffle=True)

from sklearn.model_selection import GridSearchCV

estimator = XGBClassifier(
    objective= 'binary:logistic',
    nthread=4,
    seed=42,
    
)

parameters = {
    'max_depth': range (2, 10, 1),
    'n_estimators': range(60, 1000, 40),
    'learning_rate': [0.1, 0.01, 0.05]
}

grid_search = GridSearchCV(
    estimator=estimator,
    param_grid=parameters,
    scoring = 'f1',
    n_jobs = 10,
    cv = 10,
    verbose=True
)

grid_search.fit(X, Y)

# fit model no training data
from xgboost import XGBClassifier

#model = XGBClassifier(n_estimators=450,max_depth=40,random_state=1,objective= 'binary:logistic',)
model = model = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
              colsample_bynode=1, colsample_bytree=1, gamma=0,
              learning_rate=0.1, max_delta_step=0, max_depth=4,
              min_child_weight=1, missing=None, n_estimators=380, n_jobs=1,
              nthread=4, objective='binary:logistic', random_state=0,
              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42,
              silent=None, subsample=1, verbosity=1)

model.fit(X_train, y_train)

# make predictions for test data
y_pred = model.predict(X_test)
predictions = [round(value) for value in y_pred]

# evaluate predictions

from sklearn.metrics import f1_score

f1 = f1_score(y_test, predictions, average='macro')
f1

y_test.value_counts()

predictions.count(0)

confusion_matrix(y_test, predictions)



#0.830574187424334
array([[ 320,  227],
       [  62, 5060]])

##########################model recreate

new_model = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
              colsample_bynode=1, colsample_bytree=1, gamma=0,
              learning_rate=0.1, max_delta_step=0, max_depth=4,
              min_child_weight=1, missing=None, n_estimators=380, n_jobs=1,
              nthread=4, objective='binary:logistic', random_state=0,
              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42,
              silent=None, subsample=1, verbosity=1)

new_model.fit(X, Y)





###########################################

test_df = pd.read_csv('/content/drive/My Drive/Ride_Fare/test.csv',index_col="tripid")

test_df

test_df.drop('drop_time',axis = 1,inplace=True)
test_df.drop('pickup_time',axis = 1,inplace=True)



########### distance harvesian

num_rows=test_df.shape[0]
distance_list = []

for i in range(num_rows):
  pick_lon = test_df.iloc[i]['pick_lon'] 
  pick_lat = test_df.iloc[i]['pick_lat'] 
  drop_lon =  test_df.iloc[i]['drop_lon']
  drop_lat =  test_df.iloc[i]['drop_lat']
  dist = haversine(pick_lon,pick_lat,drop_lon,drop_lat)
  distance_list.append(dist)

test_df['distance'] = distance_list



test_df.drop('pick_lat',axis = 1,inplace=True)
test_df.drop('pick_lon',axis = 1,inplace=True)
test_df.drop('drop_lat',axis = 1,inplace=True)
test_df.drop('drop_lon',axis = 1,inplace=True)

test_df

#################m using new odel



### NN
test_preds = new_model.predict(test_df)

test_preds

submission_df = pd.read_csv('/content/drive/My Drive/Ride_Fare/sample_submission.csv',index_col="tripid")
submission_df.head()



# Make sure we have the rows in the same order


# Save predictions to submission data frame
submission_df["prediction"] = test_preds

submission_df.head()

# 1_1 clas wight, H= all data, L = part
submission_df.to_csv('/content/drive/My Drive/Ride_Fare/ride_fare_submission_xgb_410z_5285o.csv', index=True)

submission_df['prediction'].value_counts()

################## using same model



### NN
test_preds = model.predict(test_df)

test_preds

submission_df = pd.read_csv('/content/drive/My Drive/Ride_Fare/sample_submission.csv',index_col="tripid")
submission_df.head()



# Make sure we have the rows in the same order


# Save predictions to submission data frame
submission_df["prediction"] = test_preds

submission_df.head()

# 1_1 clas wight, H= all data, L = part
submission_df.to_csv('/content/drive/My Drive/Ride_Fare/ride_fare_submission_xgb_379z.csv', index=True)

submission_df['prediction'].value_counts()







